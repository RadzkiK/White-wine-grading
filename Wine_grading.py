# -*- coding: utf-8 -*-
"""wina.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YceoA5RxNgudRK1ZkgXEDnA8YLhRf5Dh

Projekt zaliczeniowy z przedmiotu **Eksploracyjna analiza danych**, na wydziale Matematyki i Informatyki. Projekt polega na przewidzeniu oceny jakości wina na podstawie jego wartości fizyczno-chemicznych.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dane = pd.read_csv('white_wine.csv', sep=";")

dane.columns

for kolumna in dane.columns:
    print(kolumna, ' : ', dane[kolumna].unique())
    print('\n')

for kolumna in dane.columns:
    print(kolumna, ' : ', dane[kolumna].describe())
    print('\n')

"""Jak możemy zauważyć w danych pojawiły się wartości typu object, my chcielibyśmy by były to wartości float, poza tym pojawiły się wartości w rodzaju ',445', można podejrzewać, iż prawidłowa wartość wynosiłaby w takim przypadku 0.445, tak też konwertuje te wartości program Microsoft Excel."""

for col in dane.columns:
    dane[col] = dane[col].apply(lambda x: float(x.replace(',', '.')) if isinstance(x, str) and ',' in x else x)

"""W pierwszej kolejności zamieniliśmy przecinki na kropki i przekonwertowaliśmy takie obiekty na liczby typu float, ale przez warunek posiadania przecinka w obiekcie nie przekonwertowało nam to liczb całkowitych. Poprawy to."""

for col in dane.columns:
    dane[col] = dane[col].apply(lambda x: float(x) if isinstance(x, str) else x)

"""Użyjmy funkcji info() na przekonwertowanych danych."""

dane.info()

"""Jak widać nasze dane posiadają teraz wartości float64, tak ujednolicone będą przyjemniejsze do pracy. Możemy też zauważyć, że nie istanieją wartości null-owe. Sprawdźmy czy nie ma duplikatów."""

dane.duplicated().any()

"""Możemy zauważyć, że trafiły nam się duplikaty w danych, uzyskajmy więcej informacji na ten temat."""

dane[dane.duplicated(keep=False)]

"""Jak możemy zauważyć mamy duże powtórzeń danych w naszym zbiorze, może to zaburzyć działanie naszego modelu, sprawdźmy ile z nich możemy usunąć."""

len(dane[dane.duplicated()])

"""Możemy usunąć aż 645 duplikaty! Usuniemy je."""

dane.drop_duplicates(inplace=True)
dane

"""Jak widać mamy teraz 3289 rekorów, wcześniej było to 3934. Nasz zbiór danych jest lżejszy, algorytmy które wykorzystamy będą działać sprawniej.

Podzielmy nasze dane na zbiór uczący oraz testowy.
"""

seed = 308161
x = dane.iloc[:,:-1]
y = dane['quality']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=seed,stratify=y)

len(x_train) / (len(x_train) + len(x_test)), len(x_test) / (len(x_train)+len(x_test))

"""Dane zostały podzielone, możemy przejść do wykonania eksploracyjnej analizy danych na zbiorze uczącym."""

for kolumna in dane.columns:
    print(kolumna, ' : ', dane[kolumna].describe())
    print('\n')

"""Po przeanalizowaniu podstawowych statystyk naszych danych możemy zauważyć pewne własności. Pierwszą z nich jest fakt, że średnie oraz miediany mają bardzo zbliżone do siebie wartości, może to sugerować dobre zróżnicowanie danych bez nieporządanych dziur i proporcjonalną ilość obserwacji ze skrajnymi wartościami.
Można również spostrzec dużą amplitudę w wartościach niektórych zmiennych, takich jak: lotna kwasowość, kwas cytrynowy, cukier resztkowy, chlorki, wolny i całkowity dwutlenek siarki. Ciężko powiedzieć w jaki sposób oddziałuje to na ocenę jakości wina, z tego co można śmiało powiedzieć to fakt, że ważnymi elementami w ocenie wina są na pewno kwasowość oraz cukier resztkowy. Poza tym najważniejszymi elementami przy ocenie są alkohol, siarczany oraz gęstość.

Przejdźmy do stworzenia macierzy korelacji naszych zmiennych jak i również zmienną celu.
"""

data = pd.merge(left=x_train, right=y_train, left_index=True, right_index=True)
data

plt.figure(figsize=(12,10))
sns.heatmap(data.corr(),annot=True,cmap="magma",fmt='.2f')
plt.show()
plt.savefig('korelacje.png')

"""Z analizy korelacji naszych zmiennych wynika, że mocno skorelowane są ze sobą takie pary jak: {gęstość, cukier resztkowy}, {gęstość, alkohol}, {gęstość, całkowity dwutlenek siarki}, {wolny dwutlenek siarki, całkowity dwutlenek siarki}. Poza tym wiemy, że zmienna celu najmocniej jest skorelowana ze zmiennymi: alkohol, gęstość z odpowiednio wartościami korelacji: 0.43 oraz -0.30. Będą to najprawdopodobniej dwa najważniejsze predyktory.

Przejdźmy do sprawdzenia rozkładów naszych zmiennych.
"""

plt.figure(figsize=(16,7))
sns.histplot(data['fixedacidity'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład stałej kwasowości')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład stałej kwasowości')

"""Rozkład **stałej kwasowości** jest bardzo zbliżony do rozkładu normalnego."""

plt.figure(figsize=(16,7))
sns.histplot(data['volatileacidity'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład lotnej kwasowości')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład lotnej kwasowości')

"""W przypadku zmiennej **lotna kwasowość** istnieje wyraźna asymetria prawostronna."""

plt.figure(figsize=(16,7))
sns.histplot(data['citricacid'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład kwasu cytrynowego')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład kwasu cytrynowego')

"""W przypadku **kwasu cytrynowego** również widać asymetrię prawostronną, poza tym widać niewielkie zaburzenia rozkładu normalnego przy wartości około 0.5."""

plt.figure(figsize=(16,7))
sns.histplot(data['residualsugar'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład cukru resztkowego')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład cukru resztkowego')

"""**Cukier resztkowy** nie wykazuję rozkładu normalnego, bardziej przypomina to stosunek odwrotnie proporcjonalny, im większy poziom cukru tym mniejsza ilość takich obserwacji."""

plt.figure(figsize=(16,7))
sns.histplot(data['chlorides'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład chlorków')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład chlorków')

"""W wypadku **chlorków** widać bardzo wyraźną asymetrię prawostonną."""

plt.figure(figsize=(16,7))
sns.histplot(data['freesulfurdioxide'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład wolnego dwutlenku siarki')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład wolnego dwutlenku siarki')

"""Po raz kolejny asymetria prawostronna."""

plt.figure(figsize=(16,7))
sns.histplot(data['totalsulfurdioxide'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład całkowitego dwutlenku siarki')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład całkowitego dwutlenku siarki')

"""Rozkład całkowitego dwutlenku siarki jest podobny do rozkładu normalnego."""

plt.figure(figsize=(16,7))
sns.histplot(data['density'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład gęstości')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład gęstości')

"""Rozkład **gęstości** również wykazuje silną asymetrię prawostronną."""

plt.figure(figsize=(16,7))
sns.histplot(data['pH'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład pH')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład pH')

"""Rozkład **pH** wyraźnie przypomina rozkład normalny z **delikatną** asymetrią prawostroną"""

plt.figure(figsize=(16,7))
sns.histplot(data['sulphates'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład siarczanów')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład siarczanów')

"""Rozkład **siarczanów** przypomina rozkład normalny z asymetrią prawostronną."""

plt.figure(figsize=(16,7))
sns.histplot(data['alcohol'], bins=20, color='skyblue', kde=True)
plt.title('Rozkład alkoholu')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład alkoholu')

"""Rozkład **alkoholu** odbiega od rozkładu normalnego.

Sprawdźmy jeszcze rozkład naszej zmiennej celu.
"""

plt.figure(figsize=(16,7))
sns.histplot(data['quality'], bins=7, color='skyblue', kde=True)
plt.title('Rozkład jakości wina')
plt.ylabel('Częstość')
plt.xlabel('Wartości')
plt.savefig('Rozkład jakości wina')

"""Widać zaburzenie w krzywej rozkładu, wiadome jest, że wartości są całkowite, aczkolwiek w danych są oznaczone teraz jako wartości rzeczywsite, z tego względu sprawdza nam to również wartości takie jak 3.5 które nie istnieją. Można jednak samemu śmiało stwierdzić, że nasza zmienna celu ma rozkład mocno przypominający rozkład normalny.

Przejdźmy do stworzenia modelu klasyfikacji. W tym celu użyjemy modelu opartego na algorytmie XGBoost, jest to bardzo efektywny algorytm, który powinien osiągnąć dobre wyniki. Najpierw musimy zainstalować pakiet xgboost.
"""

!pip install xgboost
import xgboost as xgb

"""Żeby nauczyć nasz model oparty o XGBoost najpierw musimy zakodować wartości naszej zmiennej celu na styl: [0,1,2,3,4,5,6] ze względu na wymagania algorytmu."""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train = le.fit_transform(y_train)
xg_clf = xgb.XGBClassifier(objective ='multi:softmax', num_class = 7, n_estimators = 150, colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 20, seed=seed)
xg_clf.fit(x_train, y_train)

Y_test = le.fit_transform(y_test)
print(xg_clf.score(x_train, y_train))
print(xg_clf.score(x_test, Y_test))

"""Jak widać na pierwszy rzut oka, nasz model jest mocno przeuczony, upewnijmy się sprawdzając założone statystyki dla naszych modeli."""

def ocena_modelu_z_odstepstwem(y_true, y_pred):
    """
    Ocena jakości modelu z dopuszczalnym odstępstwem o 1.

    Parameters:
    - y_true (list): Lista zawierająca prawdziwe wartości.
    - y_pred (list): Lista zawierająca przewidziane wartości przez model.

    Returns:
    - accuracy (float): Trafność modelu z uwzględnieniem dopuszczalnego odstępstwa o 1.
    """
    correct_predictions = 0

    for true_value, pred_value in zip(y_true, y_pred):
        if true_value - 1 <= pred_value <= true_value + 1:
            correct_predictions += 1

    accuracy = correct_predictions / len(y_true)
    return accuracy

def ocena_modelu(y_true, y_pred):
    """
    Ocena jakości modelu

    Parameters:
    - y_true (list): Lista zawierająca prawdziwe wartości.
    - y_pred (list): Lista zawierająca przewidziane wartości przez model.

    Returns:
    - accuracy (float): Trafność modelu
    """
    correct_predictions = 0

    for true_value, pred_value in zip(y_true, y_pred):
        if pred_value == true_value:
            correct_predictions += 1

    accuracy = correct_predictions / len(y_true)
    return accuracy

from sklearn.metrics import mean_absolute_error
def oblicz_mae(y_true, y_pred):
    """
    Obliczanie błędu MAE (Mean Absolute Error).

    Parameters:
    - y_true (list): Lista zawierająca prawdziwe wartości.
    - y_pred (list): Lista zawierająca przewidziane wartości przez model.

    Returns:
    - mae (float): Wartość błędu MAE.
    """
    return mean_absolute_error(y_true, y_pred)

y_train_pred = xg_clf.predict(x_train)
y_test_pred = xg_clf.predict(x_test)

y_test_pred = le.inverse_transform(y_test_pred)

print("Trafność na zbiorze uczącym: ", round(ocena_modelu(y_train, y_train_pred), 3))
print("Trafność na zbiorze testowym: ", round(ocena_modelu(y_test, y_test_pred), 3))

print("Trafność z odstępstwem o 1 na zbiorze uczącym: ", round(ocena_modelu_z_odstepstwem(y_train, y_train_pred), 3))
print("Trafność z odstępstwem o 1 na zbiorze testowym: ", round(ocena_modelu_z_odstepstwem(y_test, y_test_pred), 3))

print("Średni błąd bezwględny dla zbioru uczącego: ", round(oblicz_mae(y_train, y_train_pred), 3))
print("Średni błąd bezwględny dla zbioru testowego: ", round(oblicz_mae(y_test, y_test_pred), 3))

"""Wyniki dla zbioru uczącego są idealne, natomiast zbiór testowy wypada całkiem słabo, wyraźne przeuczenie modelu, do poprawy przejdziemy za chwilę. Sprawdźmy jeszcze ważność predyktorów w tym modelu."""

def waznosc_predyktorow(drzewo):
  waznosci = pd.Series(drzewo.feature_importances_, index=x_train.columns)
  waznosci.sort_values(inplace=True)
  waznosci.iloc[-11:].plot(kind='barh', figsize=(6,4))
waznosc_predyktorow(xg_clf)

"""Jak podejrzewaliśmy najważniejszymi predyktorami były alkohol oraz gęstość. Widać jednak, że jest dużo zmiennych które mają prawie takie samo znaczenie dla oceny modelu. Dokładniej mówiąc nie ma takiej zmiennej, która nie odegrałby istotnej roli w tworzeniu modelu."""

plt.scatter(y_test, y_test_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', label='Idealna zgodność')
plt.xlabel('Rzeczywiste wartości (y_test)')
plt.ylabel('Przewidywane wartości (y_pred)')
plt.title('Wykres wartości przewidywanych względem obserwowanych na zbiorze testowym')
plt.legend()
plt.show()

"""Narysowanie wykresu obserwacji rzeczywistych do przewidywanych pokazuje istotny fakt w modelu. Model nie przewiduje poprawnej oceny jakości wina dla win o ocenach skrajnych. Nie znalazły się obserwacje zaklasyfikowane jako wina o jakości: 1, 6 ani 7. Poza tym model klasyfikuje wina z najwyższymi ocenami jako wina o jakości 4 lub 5, czy to może oznaczać, że te wina mają bardzo podobne wyniki testów fizyko-chemicznych? Model jest mocno przeuczony, następny model może nas zbliżyć do odpowiedzi."""

from sklearn.model_selection import RandomizedSearchCV
hiperparameters = {
    'n_estimators':[100, 150, 300, 500],
    'max_depth':[5, 10, 15, 20],
    'grow_policy': ['depthwise', 'lossguide'],
    'subsample': [0, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],
    'gamma':[2, 3, 4, 5, 10, 15],
    'colsample_bytree':[0.1, 0.2, 0.3, 0.4, 0.5],
    'learning_rate':[0.01, 0.02, 0.05, 0.1, 0.2, 0.3],
    'reg_alpha':[0, 0.2, 0.4, 0.6, 0.8, 1],
    'reg_lambda':[0, 0.2, 0.4, 0.6, 0.8, 1]
}
xg_searched = RandomizedSearchCV(xgb.XGBClassifier(objective ='multi:softmax', num_class = 7, seed=seed), hiperparameters, n_iter= 1000)
xg_searched.fit(x_train, y_train)
xg_searched.best_params_, xg_searched.best_score_

"""Po 40 minutach działania kalkulacji zostały nam zwrócone następujące paramtery: {
  'subsample': 0.6,
  'reg_lambda': 0.2,
  'reg_alpha': 0.4,
  'n_estimators': 500,
  'max_depth': 15,
  'learning_rate': 0.3,
  'grow_policy': 'depthwise',
  'gamma': 5,
  'colsample_bytree': 0.2
}
Oceńmy model z takimi parametrami.


"""

xg_searched = xgb.XGBClassifier(objective ='multi:softmax', num_class = 7, subsample = 0.6, reg_lambda = 0.2, reg_alpha = 0.4, n_estimators = 500, max_depth = 15, learning_rate = 0.3, grow_policy = 'depthwise', gamma = 5, colsample_bytree = 0.2, seed=seed)
xg_searched.fit(x_train, y_train)

"""*powyższy kod został przygotowany do szybkiego stworzenia modelu o parametrach znalezionych przez RandomizedSearchCV by nie tracić czasu przy poźniejszej pracy*"""

y_train_pred = xg_searched.predict(x_train)
y_test_pred = xg_searched.predict(x_test)

y_test_pred = le.inverse_transform(y_test_pred)

print("Trafność na zbiorze uczącym: ", round(ocena_modelu(y_train, y_train_pred), 3))
print("Trafność na zbiorze testowym: ", round(ocena_modelu(y_test, y_test_pred), 3))

print("Trafność z odstępstwem o 1 na zbiorze uczącym: ", round(ocena_modelu_z_odstepstwem(y_train, y_train_pred), 3))
print("Trafność z odstępstwem o 1 na zbiorze testowym: ", round(ocena_modelu_z_odstepstwem(y_test, y_test_pred), 3))

print("Średni błąd bezwględny dla zbioru uczącego: ", round(oblicz_mae(y_train, y_train_pred), 3))
print("Średni błąd bezwględny dla zbioru testowego: ", round(oblicz_mae(y_test, y_test_pred), 3))

"""Wyniki uzyskane przez ten model nie pokazują efektu przeuczenia, aczkolwiek model nie uzyskał prawie żadnej poprawy w wynikach na zbiorze testowym względem naszego przeuczonego modelu. Po sprawdzeniu kilku róznych opcji nie udało mi się uzyskać lepszych wyników dla naszego modelu, co więcej przy oddzielnej próbie stworzenia modeli za pomocą drzew CART, C5, czy wielorakiej regresji liniowej uzyskałem znacznie gorsze wyniki dla przedstawionych danych. Sprawdźmy jak wyglądają ważności predyktorów w tym modelu."""

waznosc_predyktorow(xg_searched)

"""O dziwo alkohol spradł w ważności predyktorów, z pierwszego miejsca znalazł się na 4. Najważniejszym czynnikiem w tym wypadku okazała się gęstość, poza tym dalej wszystkie predyktory odgrywają swoją rolę w działaniu modelu."""

plt.scatter(y_test, y_test_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', label='Idealna zgodność')
plt.xlabel('Rzeczywiste wartości (y_test)')
plt.ylabel('Przewidywane wartości (y_pred)')
plt.title('Wykres wartości przewidywanych względem obserwowanych na zbiorze testowym')
plt.legend()
plt.show()

"""Poprawiony model dalej nie odgaduje poprawnie win o skrajnych jakościach, również wina o jakościach 6 czy 7 klasyfikuje jako wina o jakościach 4 lub 5. Ten model nie jest idealny, możliwe że nadaje się do oceny jakości średnich win, jednak na pewno nie nadaje się do znajdowania win o wysokiej jakości. Taką ocene lepiej pozostawić ekspertom.

Dodajmy teraz nasze wartości do zmiennej *data*.
"""

y_train_pred = le.inverse_transform(y_train_pred)

test_data = pd.merge(left=x_test, right=y_test, left_index=True, right_index=True)

data['quality_class'] = y_train_pred
test_data['quality_class'] = y_test_pred

"""Przejdźmy do stworzenia modelu szacowania o oparte dane. Tym razem stworzymy model oparty o sieci neuronowe, aby skrócić pracę od razu przejdziemy do znalezienia najlepszych hiperparametrów dla naszego modelu, również poprzez przeszukanie klasą **RandomizedSearchCV**

W pierwszej kolejności jednak znormalizujemy nasze zmienne, ponieważ tego wymaga implementacja sieci neuronowych w pakiecie sklearn.
"""

from sklearn.compose import make_column_selector
sel_num = make_column_selector(dtype_include=['int64', 'float64'])
sel_num(x)

"""Stwórzmy odpowiedni ColumnTransformer:"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import MinMaxScaler

preprocesor = ColumnTransformer(transformers =
                                [('num', MinMaxScaler(feature_range = (-1,1)), sel_num)])
preprocesor

"""Jak wyglądają nasze zmienne po normalizacji?"""

tmp = preprocesor.fit_transform(x_train)
pd.DataFrame(tmp, columns = preprocesor.get_feature_names_out())

"""Musimy jeszcze przywrócić prawdziwe kategorie na zmiennej celu w zbiorze treningowym."""

y_train = le.inverse_transform(y_train)

"""Stwórzmy pipeline, który odpowie za transformację naszych danych oraz wygeneruje model regresji do optymalizacji."""

from sklearn.pipeline import Pipeline
from sklearn.neural_network import MLPRegressor
pipeline_1 = Pipeline(steps = [('prep', preprocesor),
                           ('siec', MLPRegressor(random_state=seed))
                          ]
                 )
pipeline_1

pipeline_1.fit(x_train, y_train)

"""Teraz przygotujemy przestrzeń hiperparametrów do przeszukania najlepszej kombinacji."""

param_dist = {
    'siec__hidden_layer_sizes': [(50,), (100,), (150,), (50, 50), (100, 100)],
    'siec__activation': ['logistic', 'tanh', 'relu'],
    'siec__alpha': 10.0 ** -np.arange(1, 7),
    'siec__learning_rate': ['constant', 'invscaling', 'adaptive'],
    'siec__max_iter': [100, 200, 400, 700, 1000, 1500],
    'siec__solver' : ['adam', 'lbfgs', 'sgd']
}

from sklearn.model_selection import RandomizedSearchCV
random_search = RandomizedSearchCV(pipeline_1, param_distributions=param_dist, n_iter=200, n_jobs=-1, random_state=seed)

random_search.fit(x_train, y_train)
print("Best parameters: ", random_search.best_params_)

"""Po dość długim oczekiwaniu na wynik algorytmu parametry jakie zostały nam zwrócone to: {
  'siec__solver': 'adam', 'siec__max_iter': 1000, 'siec__learning_rate': 'invscaling', 'siec__hidden_layer_sizes': (150,), 'siec__alpha': 0.01, 'siec__activation': 'relu'
}

Stwórzmy teraz model z wybranymi parametrami.
"""

from sklearn.pipeline import Pipeline
from sklearn.neural_network import MLPRegressor
pipeline_2 = Pipeline(steps = [('prep', preprocesor),
                           ('siec', MLPRegressor(random_state=seed, solver='adam', max_iter=1000, learning_rate='invscaling', alpha=0.01, activation='relu', hidden_layer_sizes=(150,)))
                          ]
                 )
pipeline_2

pipeline_2.fit(x_train, y_train)

y_train_pred_mlp = pipeline_2.predict(x_train)
y_test_pred_mlp = pipeline_2.predict(x_test)

for i, item in enumerate(y_train_pred_mlp):
        y_train_pred_mlp[i] = round(item)

for i, item in enumerate(y_test_pred_mlp):
        y_test_pred_mlp[i] = round(item)

print("Trafność na zbiorze uczącym: ", round(ocena_modelu(y_train, y_train_pred_mlp), 3))
print("Trafność na zbiorze testowym: ", round(ocena_modelu(y_test, y_test_pred_mlp), 3))

print("Trafność z odstępstwem o 1 na zbiorze uczącym: ", round(ocena_modelu_z_odstepstwem(y_train, y_train_pred_mlp), 3))
print("Trafność z odstępstwem o 1 na zbiorze testowym: ", round(ocena_modelu_z_odstepstwem(y_test, y_test_pred_mlp), 3))

print("Średni błąd bezwględny dla zbioru uczącego: ", round(oblicz_mae(y_train, y_train_pred_mlp), 3))
print("Średni błąd bezwględny dla zbioru testowego: ", round(oblicz_mae(y_test, y_test_pred_mlp), 3))

"""Jak widać model regresyjny ooparty o klasę MLPRegressor uzyskał bardzo podobne wyniki do modelu klasyfikacji opartego o XGBoost. Różnica między modelami jest naprawdę marginalna, dla zbioru testowego różnią się o wartości tysięczne. Model regresyjny uzyskał delikatnie lepsze wyniki dla zbioru testowego, natomiast model klasyfikacyjny wydaje się mieć bardziej stabilne wyniki, różnice między wynikami dla zbiorów są mniejsze."""

plt.scatter(y_test, y_test_pred_mlp)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', label='Idealna zgodność')
plt.xlabel('Rzeczywiste wartości (y_test)')
plt.ylabel('Przewidywane wartości (y_pred)')
plt.title('Wykres wartości przewidywanych względem obserwowanych na zbiorze testowym')
plt.legend()
plt.show()

"""Model regresyjny dalej nie jest w stanie przwidzieć poprawnie skrajnej oceny wina jak 1 lub 7, poprawił się jednak jeżeli chodzi o przewidywanie oceny 6, ale zdarzyła się sytuacja w której ocenił wino o jakości 1 jako -2, sprawdźmy ile razy wystąpiła taka anomalia."""

ilosc = 0
for element in y_test_pred_mlp:
  if element == -2:
     print(element)
     ilosc += 1
print("Ilość anomali o wartości -2: ", ilosc)

"""Widocznie trafiła się jedna taka obserwacja, musiałbyć to jakiś błąd.

Sprawdźmy informację na temat naszej sieci.
"""

def info_o_sieci(potok, krok):
    print('Liczba warstw: ',potok.named_steps[krok].n_layers_)
    print('Liczba neuronów w warstwie wejściowej: ',potok.named_steps[krok].n_features_in_)
    print('Liczba neuronów w warstwach ukrytych: ', potok.named_steps[krok].hidden_layer_sizes)
    print('Funkcja aktywacji w warstwach ukrytych : ',potok.named_steps[krok].activation)
    print('Liczba neuronów w warstwie wyjściowej: ',potok.named_steps[krok].n_outputs_)
    print('Funkcja aktywacji w warstwie wyjściowej : ',potok.named_steps[krok].out_activation_)

info_o_sieci(pipeline_2, 'siec')

"""Nasza sieć ma 3 warstwy, liczba neuronów w wartwie wejściowej odpowiada liczbie parametrów, funkcją aktywacji jest funkcja 'relu', zwraca ona wartość wejściową jeżeli jest dodatnia, w przeciwnym wypadku zwraca 0. W warstwie wyjściowej mamy jeden neuron z aktywacją identycznościową, czyli zwracana jest wartość przewidywana dla zmiennej celu."""

liczba_epok = len(pipeline_1.named_steps['siec'].loss_curve_)
plt.plot(range(1,liczba_epok+1), pipeline_1.named_steps['siec'].loss_curve_)

"""Nasza funkcja straty pokazuję dużą stabilność, po gwałtownym spadku na samym początku bardzo szybko stabilizuje się z niską stratą. Nie widać żadnych anomalii."""

data['quality_reg'] = y_train_pred_mlp
test_data['quality_reg'] = y_test_pred_mlp

"""Przejdźmy do pogrupowania naszych danych. W tym celu użyjemy klasy DBSCAN, najpierw musimy ustalić wartość parametrów konstruktora, **min_samples** bedzie równe 22 ze względu na podwojoną ilość paramterów, do znalezienia odpowiedniej wartości zmiennej **eps** zastosujemy metodę zalecaną przez twórców.


"""

from sklearn.neighbors import NearestNeighbors
k = 21
sasiedzi = NearestNeighbors(n_neighbors = k + 1)
sasiedzi.fit(x_train)
dist, ind = sasiedzi.kneighbors(x_train)

pd.DataFrame(ind).head(10)

pd.DataFrame(dist).head(10)

"""Interesują nas odległości od 21 najbliższych sąsiadów znajdujących się w ostatniej kolumnie tablicy. Posortujmy je malejąco i narysujmy wykres."""

k_dist = sorted(dist[:,-1], reverse = True)
plt.figure(figsize = (16,10))
plt.plot(k_dist)
plt.ylabel(f"Odległość od {k} najbliższego sąsiada")
plt.xlabel(f"Obserwacje posortowane względem odległości od swoich {k}-tych najbliższych sąsiadów ")
plt.show()

eps = []
for obs in [5, 10, 25, 35, 75, 150, 250, 500, 1000, 1300, 2000, 2300]:
    eps.append(round(k_dist[obs],1))
eps

"""Po przeanalizowaniu wykresu moglibyśmy stwierdzić, że łatwo znaleźć punkt w którym krzywa zmienia nachylenie, jak się okazało nie było to takie oczywiste, najpierw zostanie sprawdzona wartość wydająca się odpowiednią, jednak dalej sprawdzimy jak wygląda podział na grupy dla konkretnych wartości eps z wcześniejszego bloku kodu.

"""

from sklearn.cluster import DBSCAN
dbscan1 = DBSCAN(eps = 15.9, min_samples = 22)
dbscan1.fit(x_train)

dbscan1.labels_

pd.Series(dbscan1.labels_).value_counts().to_frame()

"""Jak widać powstały tylko dwie grupy, z czego w jednej znajduje się tylko 29 obserwacji, najwyraźniej parametr **eps** jest za duży. Spróbujmy zobaczyć jak będą wyglądały podziały przy różnych wartościach eps."""

for e in eps:
    dbscan = DBSCAN(eps = e, min_samples = 22)
    dbscan.fit(x_train)
    print('eps =', e)
    display(pd.Series(dbscan.labels_).value_counts().to_frame())

"""Podział na większą ilość grup zaczyna się przy bardzo niskim parametrze **eps** dlatego sprawdzimy 2 wartości: 6.2 oraz 4.8. Stworzy nam to podziały na odpowiednio 4 oraz 6 grup (wraz z grupą obserwacji odstających)."""

wina_gr = x_train.copy()
dbscan = DBSCAN(eps = 6.2, min_samples = 22)
dbscan.fit(x_train)
wina_gr['Cluster1'] = dbscan.labels_
dbscan = DBSCAN(eps = 4.8, min_samples = 22)
dbscan.fit(x_train)
wina_gr['Cluster2'] = dbscan.labels_

"""Sprawdzimy wynik sylwetki dla kazdego grupowania."""

import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
from sklearn.metrics import silhouette_samples, silhouette_score

def silhouette_plot(X, y_pred, n_clusters):
    fig, ax1 = plt.subplots(1, 1)
    fig.set_size_inches(18, 7)

    ax1.set_xlim([-0.1, 1])
    # The (n_clusters+1)*10 is for inserting blank space between silhouette
    # plots of individual clusters, to demarcate them clearly.
    ax1.set_ylim([0, X.shape[0] + (n_clusters + 1) * 10])

    # The silhouette_score gives the average value for all the samples.
    # This gives a perspective into the density and separation of the formed
    # clusters
    silhouette_avg = silhouette_score(X, y_pred)
    print("For n_clusters =", n_clusters,
          "The average silhouette_score is :", silhouette_avg)

    # Compute the silhouette scores for each sample
    sample_silhouette_values = silhouette_samples(X, y_pred)

    y_lower = 10
    for i in range(n_clusters):
        # Aggregate the silhouette scores for samples belonging to
        # cluster i, and sort them
        ith_cluster_silhouette_values = sample_silhouette_values[y_pred == i]

        ith_cluster_silhouette_values.sort()

        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i

        color = cm.nipy_spectral(float(i) / n_clusters)
        ax1.fill_betweenx(np.arange(y_lower, y_upper),
                          0, ith_cluster_silhouette_values,
                          facecolor=color, edgecolor=color, alpha=0.7)

        # Label the silhouette plots with their cluster numbers at the middle
        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))

        # Compute the new y_lower for next plot
        y_lower = y_upper + 10  # 10 for the 0 samples

    ax1.set_title("Wykres sylwetki")
    ax1.set_xlabel("Wartość współczynnika sylwetki")
    ax1.set_ylabel("Numer klastra")

    # The vertical line for average silhouette score of all the values
    ax1.axvline(x=silhouette_avg, color="red", linestyle="--")

    ax1.set_yticks([])  # Clear the yaxis labels / ticks
    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])


# Przed narysowaniem wykresu odrzucamy obserwacje odstające.

wina_gr1 = wina_gr[wina_gr['Cluster1'] != -1]
zmienne_numeryczne = x_train.columns

silhouette_plot(wina_gr1[zmienne_numeryczne], wina_gr1['Cluster1'],3)

"""Miara sylwetki równa 0.377 pozwala na uznanie tego grupowania za poprawne, aczkolwiek jest pełno obserwacji, które zostały absolutnie źle zaklasyfikowane. Poza tym grupa 0 jest znacznie przeważająca jeżeli chodzi o ilość obserwacji."""

wina_gr2 = wina_gr[wina_gr['Cluster2'] != -1]

silhouette_plot(wina_gr2[zmienne_numeryczne], wina_gr2['Cluster2'],5)

"""Pomimo utworzenia 3 grup o bardzo dobrym wyniku sylwetki to grupowania na 5 grup nie można uznać za poprawne, odrzucamy je. Grupy te są zbyt mało liczne by wywołały odpowiednie róznice.

Spróbujmy scharakteryzować grupy z pierwszego grupowania.
"""

wina_gr.groupby('Cluster1')['residualsugar'].describe()

"""Grupa 0 ma wyraźnie mniej słodkie wina niż pozostałe dwie grupy."""

wina_gr.groupby('Cluster1')['alcohol'].describe()

"""Grupa 0 ma wina z większą ilością alkoholu."""

wina_gr.groupby('Cluster1')['sulphates'].describe()

"""Przy siarczanach nie widać dużej róznicy między grupami."""

wina_gr.groupby('Cluster1')['pH'].describe()

"""Grupa 0 ma delikatnie większe pH niż grupy 1 i 2."""

wina_gr.groupby('Cluster1')['density'].describe()

"""Grupy 1 i 2 to wina o większej gęstości."""

wina_gr.groupby('Cluster1')['fixedacidity'].describe()

"""Grupa 2 ma średnio największą stałą kwasowość, ale również ma najmniejższy zakres tej kwasowości."""

wina_gr.groupby('Cluster1')['volatileacidity'].describe()

wina_gr.groupby('Cluster1')['citricacid'].describe()

"""Grupa 1 ma wyższe stężenie kwasu cytrynowego niż pozostałe grupy."""

wina_gr.groupby('Cluster1')['chlorides'].describe()

"""Jeżeli chodzi o chlorki to nie widać dużego zróżnicowania."""

wina_gr.groupby('Cluster1')['freesulfurdioxide'].describe()

wina_gr.groupby('Cluster1')['totalsulfurdioxide'].describe()

"""Grupy 1 oraz 2 mają wyraźnie wyższy poziom dwutlenku siarki, zarówno wolnego jak i całkowitego.

Podsumowując, można powiedzieć że grupa 0 to wina mniej słodkie, delikatnie mocniejsze oraz o krótszym terminie spożycia(wskazuje na to niższe stężenie dwutlenku siarki, odpowiedzialnego za hamowanie rozwoju drobnoustrojów oraz przeciwdziałanie utlenianiu), natomiast grupy 1 i 2 to wina słodsze, delikatniejsze w procentach, trwalsze oraz lekko kwaśniejsze. Trzeba oczywiście przypomnieć o gigantycznej przewadze w ilości win w grupie 0, oraz o fakcie zaklasyfikowania aż 764 win jako obserwacje odstające. Moim zdaniem obserwacje odstające mogłyby zostać połączone z grupami 1 i 2, tworząc w ten sposób podział na dwie grupy z możliwe, że mniejszymi ale widocznymi różnicami.

Zastosujmy jeszcze podany podział do zbioru testowego, oraz sprawdźmy czy istnieje związek między grupowaniem a jakością wina, moja intuicja podpowiada mi o braku takiego związku, ale sprawdźmy to.
"""

wina_test_gr = x_test.copy()
dbscan = DBSCAN(eps = 6.2, min_samples = 22)
dbscan.fit(x_test)
wina_test_gr['Cluster1'] = dbscan.labels_

"""Sprawdźmy jakość grupowania."""

pd.Series(dbscan.labels_).value_counts().to_frame()

"""Takie grupowanie nie sprawdziło się w przypadku zbioru testowego, zostały stworzone tylko dwie grupy z czego grupa 0 ma 229 obserwacji a grupa 1 tylko 17, natomiast największy zbiór (aż 741 obserwacji) został zaklasyfikowany jako obserwacje odstające. Sprawdźmy jakość sylwetki."""

wina_test_gr1 = wina_test_gr[wina_test_gr['Cluster1'] != -1]

silhouette_plot(wina_test_gr1[zmienne_numeryczne], wina_test_gr1['Cluster1'],2)

"""Średnia miara sylwetki wynosi 0.29 co jest poprawnym grupowaniem, ale nie uwzględnia to obserwacji odstających. Moim zdaniem takie grupowanie nie spełnia swojej roli."""

data['group'] = wina_gr['Cluster1']
test_data['group'] = wina_test_gr['Cluster1']

"""Sprawdźmy czy grupowanie ma związek z jakością wina."""

plt.figure(figsize=(12,10))
sns.heatmap(data.corr(),annot=True,cmap="magma",fmt='.2f')
plt.show()

"""Według macierzy korelacji związek między grupowaniem a jakością wina jest bardzo mały, korelacja wynosi tylko 0.13"""

data.to_csv(r"white_wine_train.csv", index=False)
test_data.to_csv(r"white_wine_test.csv", index=False)